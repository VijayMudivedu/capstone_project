---
title: "Hospital Ratings CMS"
author: "Vijay Mudivedu"
date: '2018-09-02'
output: 
  word_document: 
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
#setwd("~/Google Drive/_OneDrive_Atimi_Software/Upgrad/_Upgrad/Capstone_project/")
```


# General Information

```{r capstone}
general_info <- read.csv(file = "ValidFiles/Hospital General Information.csv",header = T,check.names = T,na.strings = c("Not Available",""),
                         stringsAsFactors = T)
head(general_info)
```

```{r}
str(general_info)
summary(general_info)
```

* This analysis is being run for Acute Care Hospitals. But the dataset contains the Acute care, Childrens, and Critical Access Hosptials. Hence filtering out all the acute care hosptials from the General Information dataset


```{r}
unique(general_info$Hospital.Type)
```


#### filtering the acute care hospitals, removing the columns not needed for analysis

```{r}
zdemographics <- c("Hospital.Name","Address","City","State","County.Name","Phone.Number","ZIP.Code")
general_info_cleaned <- general_info[,-which(names(general_info) %in% zdemographics)]
general_info_cleaned <-  general_info_cleaned[general_info_cleaned$Hospital.Type %in% "Acute Care Hospitals",-which(names(general_info_cleaned) %in% c("Hospital.Type","Hospital.Ownership","Emergency.Services","Meets.criteria.for.meaningful.use.of.EHRs"))]
str(general_info_cleaned)
summary(general_info_cleaned)
```
# Check if the NAs in the Ratings are missing at Random in the Footnote

```{r}
general_info_cleaned$Hospital.overall.rating <- as.factor(general_info_cleaned$Hospital.overall.rating)
str(general_info_cleaned)

```


* footnote with: "Data are shown only for hospitals that participate in the Inpatient Quality Reporting (IQR) and Outpatient Quality Reporting (OQR) programs" is inducing the NAs across the dataset, 
* As the IQR and OQR information is partly available. This enables us to conclude that the provider ids related this level can be purged from the dataset

```{r}
general_info_cleaned %>% filter(general_info_cleaned$Hospital.overall.rating.footnote %in% 
           c("Data are shown only for hospitals that participate in the Inpatient Quality Reporting (IQR) and Outpatient Quality Reporting (OQR) programs")) %>% group_by(Hospital.overall.rating,Mortality.national.comparison,Readmission.national.comparison,Safety.of.care.national.comparison,Efficient.use.of.medical.imaging.national.comparison,Timeliness.of.care.national.comparison,Effectiveness.of.care.national.comparison,Patient.experience.national.comparison) %>% 
  summarise(count_rws = n()) %>% t()

general_info_cleaned <- general_info_cleaned %>% 
  filter(!general_info_cleaned$Hospital.overall.rating.footnote %in% 
           c("Data are shown only for hospitals that participate in the Inpatient Quality Reporting (IQR) and Outpatient Quality Reporting (OQR) programs"))

summary(general_info_cleaned)

```
```{r}

general_info_cleaned %>% filter(general_info_cleaned$Hospital.overall.rating.footnote %in% 
           c("Data suppressed by CMS for one or more quarters")) %>% group_by(Hospital.overall.rating,Mortality.national.comparison,Readmission.national.comparison,Safety.of.care.national.comparison,Efficient.use.of.medical.imaging.national.comparison,Timeliness.of.care.national.comparison,Effectiveness.of.care.national.comparison,Patient.experience.national.comparison) %>% 
  summarise(count_rws = n()) %>% t()
#general_info_cleaned[general_info_cleaned$Hospital.overall.rating.footnote %in% c("Data suppressed by CMS for one or more quarters"),]
```
* Similarly, "Data suppressed by CMS for one or more quarters" also cannot be used for analysis as this is inducing the NAs across the datasets, which mandates to purge the dataset with missing NAs

```{r}
general_info_cleaned <- general_info_cleaned %>% filter(!general_info_cleaned$Hospital.overall.rating.footnote %in% 
           c("Data suppressed by CMS for one or more quarters"))

summary(general_info_cleaned)
```
```{r}
barplot(prop.table(table(general_info_cleaned$Hospital.overall.rating)))

```

* Barplot of the ratings show that the Hospital rating has a gaussian distribution

* checking the level footnote level of Hospital Rating 
  - "There are too few measures or measure groups reported to calculate a star rating or measure group score"
  - "Results are not available for this reporting period"



```{r}
general_info_cleaned %>% 
  filter(general_info_cleaned$Hospital.overall.rating.footnote %in% 
           c("Results are not available for this reporting period",
             "There are too few measures or measure groups reported to calculate a star rating or measure group score")) %>% summary()
```
* The above specific additional footnotes also contribute to the NAs in Hospital Overall Rating with multilevel dependency on the other groups. For example, specified ones below contribue less to NAs, compared to Mortality, Safety of care, Readmission, Efficient Use of medical Imaging.
  - "Patient.experience" , "Effectiveness.of.care", "Timeliness.of.care"

```{r}
general_info_cleaned <- general_info_cleaned %>% 
  filter(!general_info_cleaned$Hospital.overall.rating.footnote %in% 
           c("Results are not available for this reporting period",
             "There are too few measures or measure groups reported to calculate a star rating or measure group score")) 
           #c("This hospital\x92s star rating only includes data reported on inpatient services")) %>% summary()#group_by(Hospital.overall.rating) %>% summarise(n())
           #c("There are too few measures or measure groups reported to calculate a star rating or measure group score")) %>% summary()

summary(general_info_cleaned)

```

1. We thus have conclusively arrived at the "general_info_final" dataset with 1-5 hospital ratings imputing the NAs
2. Picking the hospital Rating from the general info cleaned dataset 

```{r}
z_rem_var1 <- which(names(general_info_cleaned) %in% c("Provider.ID","Hospital.overall.rating"))
general_info_final <- general_info_cleaned[is.na(general_info_cleaned$Hospital.overall.rating.footnote),z_rem_var1]

summary(general_info_final)

```



# Complications



```{r}
complications_df <- read.csv(file = "ValidFiles//Complications - Hospital.csv",
                             header = T,check.names = T,stringsAsFactors = T,na.strings = c('Not Available',""))
head(complications_df)

```

* Cleaning the demographic variables that do not have an impact on the Measure IDs

```{r}
# Remove demographic details, start_data and
zdemographics <- c("Hospital.Name","Address","City","State","ZIP.Code","County.Name","Phone.Number","Measure.Start.Date", "Measure.End.Date")
zdemogrphic_vars <- which(names(complications_df) %in% zdemographics)
complications_df_cleaned <- complications_df[,-zdemogrphic_vars]
head(complications_df_cleaned)

```
- Measuring the distribution of NAs in the Complications dataset, Compared to National, and Footnote variables.
- About 35% of the NAs in Compared to National, and 41% of the records in footnote is stale due to reasons specified in the variable.

```{r}
round(prop.table(summary(factor(complications_df_cleaned$Compared.to.National)))*100,2)  #- Thus NAs are 35% in the Compared.To.National variable
round(prop.table(summary(factor(complications_df_cleaned$Footnote)))*100,2)  #- NAs are 65% in the Footnote variable 
```

- Analysis of "footnote" variable by checking the impact on the score variable

```{r}
# Distribution of Score and Denominator by Footnote
complications_df_cleaned %>% group_by(Footnote) %>% 
  summarise(cnt_rows = n(),Avg_Score = mean(Score,na.rm = T),Total_Score = sum(Score,na.rm = T)) %>% arrange(Avg_Score)

```

- Footnote Variable: Footnote levels which have specific reasons do not contribute to score variable for the specific Provided.ID, these rows can be removed from analysis.

```{r}
zvar1 <- is.na(complications_df$Footnote) # Blank Footnotes
zvar2 <- which(names(complications_df_cleaned) %in% "Footnote")
complications_df_cleaned_footnote_nas <- complications_df_cleaned[zvar1,-zvar2]
str(complications_df_cleaned_footnote_nas)
summary(complications_df_cleaned_footnote_nas)
```
- Imputing the "NAs" resulted in inducing the variability in each of the variables. 

- Analysing the Denominator (Total Number of Admissions) variable for the reason behind the NAs.

# which variable is contributing most NAs  in "Denominator" variable?

```{r}
library(reshape2)
complications_df_cleaned_footnote_nas %>% group_by(Measure.ID) %>% 
  summarise(cnt_rws = n(), Sum_score = sum(Score,na.rm = T),
            mean_Score = mean(Score,na.rm = T)) %>% 
  arrange(desc(cnt_rws)) %>% melt(value.name = c("value")) %>%
  ggplot(aes(x = Measure.ID,y = value)) + geom_col() + facet_wrap(facets = ~ variable,scales = "free",ncol = 3) + 
  theme(axis.text.x = element_text(angle = 90,vjust = 0.5,hjust = 1))


complications_df_cleaned_footnote_nas[is.na(complications_df_cleaned_footnote_nas$Denominator),] %>% summary()

```
- NAs in the Denominator (Total number of people admitted to hospital is unknown) is due to "Serious complications/ PSI_90_Safety". Lower estimate, Higher Estimate, Scores have even distribution. Removing this data wouldn't impact the overall ddistribution of the data

- Since the Denominator is not a signficiaant variabel for analysis, there is no impact on the analysis NAs in Denomintor variable move on.
- Significant Measures from these measure Ids are "PSI_90_SAFETY","PSI_4_SURG_COMP" "COMP_HIP_KNEE" is the other significant measure

- rejecting the Denominoator, Lower Estimate, Higher Estimate, Compared.to.National variables
- Important measures are 

```{r}

zvar1 <- c( "Provider.ID", "Measure.ID", "Score")
zvar2 <- which(names(complications_df_cleaned_footnote_nas) %in% zvar1)

complications_df_final <-  complications_df_cleaned_footnote_nas[,zvar2]
summary(complications_df_final)

# spread the Mesure.IDs.
complications_df_spread <- spread(data = complications_df_final,key = Measure.ID,value = Score)
dim(complications_df_spread)
summary(complications_df_spread)
```



- Considering the signficant variable measures from these Complications Dataset

```{r}
zvar1 <- which(names(complications_df_spread) %in% c("Provider.ID","PSI_90_SAFETY","COMP_HIP_KNEE"))

complications_df_final <- complications_df_spread[,zvar1]

str(complications_df_final)

```

# Analysis for Healthcare Associated Infections - For Hosptial

```{r}
hai_df <- read.csv(file = "~/Google Drive/_OneDrive_Atimi_Software/Upgrad/_Upgrad/Capstone_project/capstone_project/ValidFiles/Healthcare Associated Infections - Hospital.csv",na.strings = c("Not Available",""))
head(hai_df)



```

```{r}
str(hai_df)
```


```{r}
summary(hai_df)
```


- remove the demographic variables, Address, City, State, ZIP.Code, County.Name,Phone.Number,Footnote

```{r}
zdemographics <- c("Hospital.Name","Address","City","State","County.Name","Phone.Number","ZIP.Code","Measure.Start.Date","Measure.End.Date")
hai_df_cleaned <- hai_df[,-which(names(hai_df) %in% c(zdemographics))]
str(hai_df_cleaned)
summary(hai_df_cleaned)
```

- Imputing the NAs from the Hospital Associated Infections dataset - Variables, Footnote with values

```{r}
hai_df_cleaned %>% group_by(Footnote) %>% summarise(count_rows = n(),score_total = sum(Score,na.rm = T))
```
- Footnote variable that briefs out the imperfections associated with the score for each related level
- Considering the blank in the footnotes that carry more weightage to the score


```{r}
zvar1 <- which(names(hai_df_cleaned) %in% c("Footnote"))
hai_df_cleaned <- hai_df_cleaned[is.na(hai_df_cleaned$Footnote),-zvar1]  

# removing the invalid footnotes and Footnote variable that do not contribute zvar
summary(hai_df_cleaned)
```

# determine the outliers in the Score

```{r}
ggplot(data = hai_df_cleaned,aes(x = hai_df_cleaned$Measure.ID,y = Score)) + 
  geom_boxplot() + xlab("Measure.ID") +
  theme(axis.text.x = element_text(angle = 90))

```

* There are abnormal outliers in the dataset from the measure IDs HAI_1_DOPC_Days, besides this they do not contribute to the overall score
- Summarise the distribution of the mueasures. 


```{r}
hai_df %>% group_by(Measure.Name,Measure.ID) %>% summarise(cnt_rws = n())
```

- A central line-associated bloodstream infection (CLABSI) is a serious infection that occurs when germs (usually bacteria or viruses) enter the bloodstream through the central line. Healthcare providers must follow a strict protocol when inserting the line to make sure the line remains sterile and a CLABSI does not occur. In addition to inserting the central line properly, healthcare providers must use stringent infection control practices each time they check the line or change the dressing. Patients who get a CLABSI have a fever, and might also have red skin and soreness around the central line. If this happens, healthcare providers can do tests to learn if there is an infection present.

-Clostridium difficile (C. difficile) is a bacteria that causes diarrhea and can lead to serious complications. Those at highest risk for C. difficile infection include people who take antibiotics and also receive care in any medical setting, including hospitals. C. difficile bacteria produce spores that can be spread from patient to patient. Symptoms from C. diff infections often take a few days to develop. Patients are tested for C. diff. infections if they show signs of illness while in the hospital. This measure compares the number of stool specimens that tested positive for C. diff toxin four or more days after the patient entered the hospital to a national benchmark.

- CAUTI -Catheter Associated Urinary Tract Infections: A urinary tract infection (UTI) is an infection involving any part of the urinary system, including urethra, bladder, ureters, and kidney. UTIs are the most common type of healthcare-associated infection reported to the National Healthcare Safety Network (NHSN).  Among UTIs acquired in the hospital, approximately 75% are associated with a urinary catheter, which is a tube inserted into the bladder through the urethra to drain urine.  Between 15-25% of hospitalized patients receive urinary catheters during their hospital stay.  The most important risk factor for developing a catheter-associated UTI (CAUTI) is prolonged use of the urinary catheter.  Therefore, catheters should only be used for appropriate indications and should be removed as soon as they are no longer needed.


- Considering the SIRs, that Centre for Diesease Control and Prevention uses to calculate. Standard Infection Ratio (SIR) which takes into account patient care location, number of patients with an exisiting infection, lab mehtords, bed size, afficialiton with a medical schools, bed size of the hospital, age of patients.

- central line-associated bloodstream infections (CLABSI), catheter- associated urinary tract infections (CAUTI), surgical site infection (SSI) from colon surgery or abdominal hysterectomy, methicillin-resistant Staphylococcus Aureus (MRSA) blood laboratory-identified events (bloodstream infections), and Clostridium difficile (C.diff.) laboratory-identified events (intestinal infections). The HAI measures show how often patients in a particular hospital contract certain infections during the couse of their medical treatment

HAI_1_SIR, HAI_1a_SIR, HAI_2_SIR, HAI_2a_SIR, HAI_6_SIR,HAI_4_SIR, HAI_5_SIR, HAI_3_SIR

HAI-1 measure tracks central-line associated bloodstream infections (CLABSI) in ICUs and select wards. 
HAI-2 measure tracks catheter-associated urinary tract infections (CAUTI) in ICUs and select wards. 
HAI-3 Surgical Site Infection from colon surgery (SSI: Colon)
HAI-4 Surgical Site Infection from abdominal hysterectomy (SSI: Hysterectomy)
HAI-5 Methicillin-resistant Staphylococcus Aureus (MRSA) Blood Laboratory-identified Events (Bloodstream infections)
HAI-6 Clostridium difficile (C.diff.) Laboratory-identified Events (Intestinal infections)


```{r}
hai_measures <- c("HAI_1_SIR", "HAI_2_SIR", "HAI_3_SIR", "HAI_4_SIR", "HAI_5_SIR", "HAI_6_SIR")

# Filterig the measure.ids useful for analysis
hai_df_cleaned <- hai_df_cleaned[which(hai_df_cleaned$Measure.ID %in% hai_measures),]

```

```{r}
ggplot(data = hai_df_cleaned,aes(x = Measure.ID,y = Score)) + 
  geom_boxplot(na.rm = T) + xlab("Measure.ID") +
  theme(axis.text.x = element_text(angle = 90))
```

```{r}
ggplot(data = hai_df_cleaned,aes(x = Measure.ID,y = Score)) + 
  geom_col(position = position_stack(),na.rm = TRUE) + xlab("Measure.ID") +
  theme(axis.text.x = element_text(angle = 90,vjust = 0.5,hjust = 1))

```



```{r}
summary(hai_df_cleaned)
```

- selecting the required columns for analysis

```{r}
zvar1 <- c( "Provider.ID", "Measure.ID", "Score")
zvar2 <- which(names(hai_df_cleaned) %in% zvar1)

hai_df_final <- hai_df_cleaned[,zvar2] %>% spread(key = "Measure.ID",value = "Score")
summary(hai_df_final)

```

# Creating a Patient Safety group

```{r}
gen_inf_compli_df <- merge(x = general_info_final,y = complications_df_final,all = TRUE, by = intersect(x = names(general_info_final),y = names(complications_df_final)))

safety_of_care_group <- merge(x = gen_inf_compli_df,y = hai_df_final,all = TRUE,by = intersect(x = names(gen_inf_compli_df),y = names(hai_df_final)))

head(safety_of_care_group)


```



# ANALYSIS OF HCAPHS SURVEY

```{r}


```









<!-- ```{r} -->

<!-- quantile(hai_df_cleaned_measure_ids$Score,probs = seq(0,1,0.01)) # 99.9 percentile and above -->
<!-- summary(quantile(hai_df_cleaned_measure_ids$Score,probs = 0.999))  -->

<!-- hai_df_no_outliers <- hai_df_cleaned_measure_ids[-which((hai_df_cleaned_measure_ids$Score >= quantile(hai_df_cleaned_measure_ids$Score,probs = 0.999))),] -->

<!-- summary(hai_df_no_outliers) -->

<!-- ggplot(hai_df_no_outliers,aes(y = Score)) + geom_boxplot() +  -->
<!--   facet_wrap(facets = "Measure.ID",scales = "free") -->

<!-- ``` -->



<!-- ```{r} -->
<!-- # Spreading the measure ids -->
<!-- hai_df_spreaded <- hai_df_no_outliers %>% spread(key = Measure.ID,value = Score,fill = 0) -->

<!-- hai_df_no_outliers %>% group_by(Compared.to.National,Measure.ID) %>% summarise(cnt_rows = n()) %>% arrange(Measure.ID,desc(cnt_rows)) %>% -->
<!--   ggplot(aes(reorder(Measure.ID,cnt_rows),cnt_rows)) + geom_col() + facet_wrap(facets = ~Compared.to.National) + xlab(label = "Measure.ID") + -->
<!--   theme(axis.text.x = element_text(angle = 90))  -->

<!-- hai_df_spreaded %>% spread(key = Compared.to.National,value = 0) -->

<!-- head(hai_df_spreaded) -->
<!-- str(hai_df_spreaded) -->
<!-- summary(hai_df_spreaded) -->

<!-- ``` -->

<!-- - standardization of scores (Measure_score - mean_score)/standard.deviation.score -->

<!-- ```{r} -->
<!-- options(scipen = 100) -->

<!-- hai_df_spreaded$HAI_1_SIR -->

<!-- round((hai_df_no_outliers$Score - mean(hai_df_spreaded$HAI_1_SIR))/sd(hai_df_spreaded$HAI_1_SIR),2) %>% summary -->



<!-- ``` -->





<!-- ```{r} -->

<!-- # standardizaing the variables -->
<!-- zcomp <-  apply(complications_df_spread[,-1],MARGIN = 2,FUN =  function(x) (x - mean(x))/sd(x)) -->
<!-- summary(zcomp) -->

<!-- library(reshape2) -->
<!-- ggplot(data = melt(zcomp),aes(value)) + geom_histogram() + facet_wrap(facets = ~Var2 , scales = "free") -->

<!-- # applying winsorization and filtering data with +/- 3Signma -->
<!-- zcomp_winsor <- winsor(x = zcomp,trim = 0.00125) -->
<!-- ggplot(data = melt(zcomp_winsor),aes(value)) + geom_histogram() + facet_wrap(facets = ~Var2 , scales = "free" ) -->

<!-- pairs.panels(zcomp_winsor,stars = TRUE,density = TRUE,pch = 21, -->
<!--                     bg = rainbow(n = ncol(zcomp_winsor))) -->


<!-- prin_spread <- princomp(zcomp_winsor,cor = T ,scores = T,covmat = NULL) -->
<!-- summary(prin_spread) -->
<!-- prin_spread$loadings -->

<!-- fa_comp <- factanal(x = zcomp_winsor,factors = 5,rotation = "varimax") -->
<!-- fa_comp -->
<!-- fa_comp$loadings -->

<!-- library(psych) -->
<!-- library(devtools) -->
<!-- #install_github(repo = "ggbiplot")#,username = vijay.mudivedu@iiitb.net,quiet = TRUE) -->
<!-- library(ggbiplot) -->
<!-- ggbiplot(prin_spread,obs.scale = 1,groups = levels(melt(zcomp_winsor)$Var2) ,var.scale = 1, ellipse = TRUE,circle = TRUE, ellipse.prob = 0.68) + -->
<!--   scale_color_discrete(name = '')  -->

<!-- screeplot(x = fa_comp,type = "l",main = "screeplt",npcs = 3) -->

<!-- fa_comp_df <- fa(r = zcomp_winsor,nfactors = 1,rotate = "varimax",fm = "pa") -->
<!-- fa_comp_df -->
<!-- ?fa() -->
<!-- summary(fa_comp_df) -->

<!-- ``` -->



<!-- Standardizing the measures -->

<!-- ```{r} -->

<!-- str(general_info_cleaned) -->
<!-- merge(general_info_cleaned) -->

<!-- ``` -->



<!-- ```{r} -->

<!-- #How is the distrbituion of measures before and after removing the footnote NAs, Cleaning up the denominators of NAs -->
<!-- complications_df_cleaned %>% group_by(Measure.ID) %>% summarise(cnt_rws = n(),avg_scr = mean(Score,na.rm = T),avg_denom = mean(Denominator,na.rm = T)) %>% arrange(desc(avg_scr)) -->
<!-- complications_df_cleaned_footnote_nas %>% group_by(Measure.ID) %>% summarise(cnt_rws = n(),avg_scr = mean(Score),avg_denom = mean(Denominator,na.rm = T)) %>% arrange(desc(avg_scr)) -->


<!-- ``` -->
<!-- - Large average scores and low denominators are due to "PSI_4_SURG_COMP: Deaths among patients with serious treatable Complications after surgery""  -->
<!-- - PSI_90_SAFETY: has no denominator score as this measure is calculated from PSI 03,06, The CMS PSI 90 is calculated from PSIs 03, 06, 08, 09, 10, 11, 12, 13, 14 and 15. -->
<!-- and low average score. Hence doesn't fit well into the scoring needs. -->
<!-- - PSI_4_SURG_COMP: induces low extreme outliers in "Denominator" variable and high extremes in "Scores" Variable -->

<!-- ### outlier scoring data -->

<!-- ```{r} -->
<!-- # distribution of outliers -->

<!-- ggplot(data = complications_df_cleaned_footnote_nas,aes(x = Score,y = Denominator,col = Measure.ID)) +  -->
<!--   geom_point(position = position_jitter()) +  -->
<!--   facet_wrap(facets = ~ Measure.ID,scales = "free") + -->
<!--   theme(legend.position = "bottom", legend.background = element_blank()) -->
<!--   #theme(legend.position = c(0.8,0.6), legend.background = element_blank()) -->

<!-- ``` -->

<!-- * Clearly, the above plot shows that data is distribeted into two chunks with a clear separation. Value scores above 100, SURG COMP and value scores below 25 for the rest measure IDs -->
<!-- * High Scores with Least Low "Denominators" in PSI_4_SURG_COMP is an outlier amoung the available set of variable levels. -->


<!-- ```{r} -->

<!-- # removing the outelier induced by "PSI_4_SURG_COMP" PSI -->
<!-- complications_df_cleaned_footnote_nas_denom_outliers <-  -->
<!--   complications_df_cleaned_footnote_nas_denom[!complications_df_cleaned_footnote_nas_denom$Measure.ID == "PSI_4_SURG_COMP",] -->

<!-- # summary of complications df after removing the outliers induced by the "PSI_4_SURG_COMP" -->
<!-- summary(complications_df_cleaned_footnote_nas_denom_outliers) -->

<!-- ``` -->


<!-- ```{r} -->

<!-- quantile(complications_df_cleaned_footnote_nas_denom_outliers$Denominator,probs =  seq(0, 1, 0.01),na.rm = T ) -->
<!-- # Plotting the outliers in the Denominators -->
<!-- plot(quantile(complications_df_cleaned_footnote_nas_denom_outliers$Denominator,probs =  seq(0, 1, 0.01),na.rm = T ), -->
<!--      main = "Outliers in Denominator", ylab = "Value of Denominators",xlab = "Index") -->

<!-- quantile(complications_df_cleaned_footnote_nas_denom_outliers$Score,probs =  seq(0, 1, 0.01),na.rm = T ) -->
<!-- plot(quantile(complications_df_cleaned_footnote_nas_denom_outliers$Score,probs =  seq(0, 1, 0.001),na.rm = T ), -->
<!--      main = "Outliers in Score", ylab = "Value of Scores",xlab = "Index") -->



<!-- ``` -->

<!-- - From the 96th percentile onwards the value of variable have started to increase steeply and outliers are identified around this percentile -->

<!-- ```{r} -->
<!-- #steady increase in the value except the last quantile last 10% of quantile values are abrupt -->
<!-- quantile(complications_df$Score,probs =  seq(0, 1, 0.01),na.rm = T ) #abrupt increase in the quantile score about 94%. -->
<!-- plot(quantile(complications_df$Score,probs =  seq(0, 1, 0.01),na.rm = T )) #abrupt increase in the quantile score about 94%. -->

<!-- ``` -->



<!-- #### Analysing the outliers futher about their significance, it can be noticed that -->

<!-- ```{r} -->
<!-- # outliers are identified in Denominator in more >99% quantile. Filter the the records that are 99% and above of denominator -->
<!-- zdenom_outliers <-  which( -->
<!--   #complications_df_cleaned_footnote_nas_denom_outliers$Denominator <=  quantile(complications_df_cleaned_footnote_nas_denom_outliers$Denominator,probs = 0.1) | -->
<!--   complications_df_cleaned_footnote_nas_denom_outliers$Denominator >=  -->
<!--                             quantile(complications_df_cleaned_footnote_nas_denom_outliers$Denominator,probs = 0.97)) -->
<!-- length(zdenom_outliers) -->

<!-- complications_df_denom_outliers <- complications_df_cleaned_footnote_nas_denom_outliers[zdenom_outliers,] -->
<!-- summary(complications_df_denom_outliers) -->
<!-- ``` -->

<!-- # eliminating the outliers in the complications cleaned dataframe -->


<!-- ```{r} -->

<!-- complications_df_cleaned_denom_non_outliers <- complications_df_cleaned_footnote_nas_denom_outliers[-zdenom_outliers,] -->
<!-- summary(complications_df_cleaned_score_non_outliers) -->

<!-- plot(quantile(complications_df_cleaned_denom_non_outliers$Denominator,probs = seq(0,1,0.01)),type = "p", -->
<!--      main = "Denominator variable after eliminating the denominator outliers", -->
<!--      ylab = "Denominator values") -->
<!-- plot(quantile(complications_df_cleaned_denom_non_outliers$Score,probs = seq(0,1,0.001)),type = "p", -->
<!--      main = "Score variable after eliminating the denominator outliers", -->
<!--      ylab = "Score values") -->
<!-- boxplot(complications_df_cleaned_denom_non_outliers$Score) -->
<!-- boxplot(complications_df_cleaned_denom_non_outliers$Denominator) -->



<!-- ``` -->



<!-- ```{r} -->

<!-- quantile(complications_df_cleaned_denom_non_outliers$Score,probs = seq(0,1,0.01)) -->

<!-- zscore_outliers <-  which( -->
<!--   complications_df_cleaned_denom_non_outliers$Score <= quantile(complications_df_cleaned_denom_non_outliers$Score,probs = 0.11) | -->
<!--   complications_df_cleaned_denom_non_outliers$Score >= quantile(complications_df_cleaned_denom_non_outliers$Score,probs = 0.99)) -->
<!-- length(zscore_outliers) -->

<!-- # Verfiying the outliers in Score variable after identify and removing the outliers in"Score" variable -->
<!-- complications_df_score_outliers <- complications_df_cleaned_denom_non_outliers[zscore_outliers,] -->
<!-- summary(complications_df_score_outliers) -->

<!-- ``` -->
<!-- - Large set of records from Post_HIP measure are being cleansed due to very low values of This level  -->

<!-- ```{r} -->
<!-- complications_df_score_non_outliers <- complications_df_cleaned_denom_non_outliers[-zscore_outliers,] -->
<!-- summary(complications_df_score_non_outliers) -->
<!-- summary(complications_df_score_non_outliers$Measure.ID) -->

<!-- ``` -->



<!-- ```{r} -->
<!-- # Applying log transformation to convert the log distribution of denominator and normalizing the variable.  -->
<!-- plot(quantile(log(complications_df_cleaned_footnote_nas_denom_outliers$Score),probs =  seq(0, 1, 0.01),na.rm = T ),  -->
<!--      main = "Score - after outerliers removed from Score", -->
<!--      ylab = "Score with values") -->
<!-- plot(quantile(log(complications_df_cleaned_footnote_nas_denom_outliers$Denominator),probs =  seq(0, 1, 0.01),na.rm = T )) -->

<!-- #After removing the outliers -->
<!-- plot(quantile(log(complications_df_score_non_outliers$Score),probs =  seq(0, 1, 0.01)),main = "Score - after outerliers removed from Score", -->
<!--     ylab = "Score with values") -->
<!-- plot(quantile(log(complications_df_score_non_outliers$Denominator),probs =  seq(0, 1, 0.01)), main = "Denominator after outerliers from Score",ylab = "Denominator Values") -->

<!-- ``` -->

<!-- - Several of the values have been straightened out and 8 important measures are identified. -->

<!-- # cleaning the unwanted variables Measure.Name, ZipCode -->
<!-- ```{r} -->
<!-- zredundant_vars <- -->
<!--   which(names(complications_df_score_non_outliers) %in%  -->
<!--           c("Measure.Name","ZIP.Code","Lower.Estimate","Higher.Estimate","Denominator")) -->
<!-- complications_df_score_non_outliers_spread <- complications_df_score_non_outliers[,-zredundant_vars] -->

<!-- complications_df_spread <-  complications_df_score_non_outliers_spread %>% spread(key = Measure.ID,value = Score,fill = 0)# %>% head() -->
<!-- str(complications_df_spread) -->

<!-- prop.table(table(complications_df_spread$Compared.to.National))*100 -->

<!-- ``` -->
<!-- -  Complications variable has inequal spread of variables -->

<!-- ```{r} -->
<!-- ggplot(data = complications_df_score_non_outliers_spread,aes(x = Measure.ID,y = Score)) + geom_boxplot() + -->
<!--   theme(axis.text.x = element_text(angle = 90)) -->
<!-- ``` -->



```{r}
# hai_df_cleaned_outliers <- hai_df_cleaned[which(hai_df_cleaned$Score %in% boxplot.stats(hai_df_cleaned$Score,coef = 1.58)$out),]
# hai_df_cleaned_non_outliers <- hai_df_cleaned[-which(hai_df_cleaned$Score %in% boxplot.stats(hai_df_cleaned$Score,coef = 1.58)$out),]
# 
# summary(hai_df_cleaned_non_outliers)
# 
# ggplot(data = hai_df_cleaned_non_outliers,aes(x = Measure.ID,y = Score)) + 
#   geom_boxplot() + #xlab("Measure.ID") +
#   theme(axis.text.x = element_text(angle = 90))
# 
# quantile(x = hai_df_cleaned_non_outliers$Score,probs = seq(0,1,0.01))
# 
# hai_df_no_outliers <- hai_df_cleaned_non_outliers[which((hai_df_cleaned_non_outliers$Score >= quantile(hai_df_cleaned_non_outliers$Score,probs = c(0.15)) &
#                                                         hai_df_cleaned_non_outliers$Score <= quantile(hai_df_cleaned_non_outliers$Score,probs = c(0.9))))
#                                                   ,]
# str(hai_df_no_outliers)
# summary(hai_df_no_outliers)
# 
# hai_df_spreaded <- hai_df_no_outliers %>% spread(key = Measure.ID,value = Score,fill = 0) #%>% head()
# hai_df_spreaded %>% head()
# 
# ggplot(data = hai_df_no_outliers,aes(x = Measure.ID,y = Score)) + 
#   geom_boxplot() + #xlab("Measure.ID") +
#   theme(axis.text.x = element_text(angle = 90))
# 
# ggplot(hai_df_no_outliers,aes(Score)) + geom_histogram() +
#   facet_wrap(~Measure.ID,scales = "free")


```



```{r}
# # 2. check outliers in the measures
# compli_bxplt_outliers <- boxplot.stats(complications_df_cleaned$Score,coef = 1.58)$out
# boxplot(complications_df$Score)
# compli_bxplt_outliers
# 
# complications_df_cleaned_score_outliers <-  complications_df_cleaned[which(complications_df_cleaned$Score %in% compli_bxplt_outliers),]
# head(complications_df_cleaned_score_outliers)
# summary(complications_df_cleaned_score_outliers) 
# #There are no NAs in outliers
# # intrestingly most of the outliers are in measures Surgical Complications PSI_4_SURG_COMP, Blood Stream infection after surgery
# 
# # Which hospitals are contributing to most outlier scores?
# complications_df_cleaned_score_outliers %>% group_by(factor(Provider.ID), Hospital.Name) %>% summarise(cnt_row = n()) %>% arrange(desc(cnt_row))
# 
# # Which state is contributing to outlier scores in complications dataset? 
# complications_df_cleaned_score_outliers %>% group_by(ZIP.Code) %>% summarise(cnt_rows = n()) %>% arrange(desc(cnt_rows)) #Houston's County and LA Counts
# 
# # spreading the measures by their scores
# complications_df_cleaned_score_outliers %>% filter(ZIP.Code == "77030")  %>% spread(key = Measure.ID,value = Score,fill = 0)  
# 
# histogram(complications_df_cleaned_score_outliers$Score) # outliers are skewing the dataset heavily. 50% of the outliers are too small consider. Eliminating the lower values 
# 
# # how many records are lower than the median value in outliers
# sum(complications_df_cleaned_score_outliers$Score < median(complications_df_cleaned_score_outliers$Score))/nrow(complications_df_cleaned_score_outliers)
# # about 1870/3742 - approximately 50% of records lower than the median value. 
# 
# #Eliminating the outliers that cannot be measure
# complications_df_cleaned_score_outliers_lower_tail_purged <- 
#   complications_df_cleaned_score_outliers[!(complications_df_cleaned_score_outliers$Score < 
#                                               20#median(complications_df_cleaned_score_outliers$Score)
#                                             ),] 
# 
# histogram(complications_df_cleaned_score_outliers_lower_tail_purged$Score)

```



#-------------------------
#-Data preparation
#--------------------

Different things to be checked
1. Check if there are any duplicate measures
2. check outliers in the measures
3. Remove unwanted rows/columns
4. imputing missing values
5. convert all characters to lower case
6. check for invalid characters

Numeric variables in complications dataframe are:

```{r}
# Remove unwanted Rows

```



```{r}

zcomp <- sapply(complications_df,class)
int_comp_var <- which(zcomp %in% c("integer",'numeric'))
char_comp_var <- which(zcomp %in% c("factor"))

complications_df[char_comp_var] <- sapply(complications_df[char_comp_var], tolower)
head(complications_df)
```


```{r}
#missing value imputation
sapply(complications_df,function(x) sum(is.na(x))) # distribution of NAs
```
There are significant number of NAs in the dataset in Score, Lower Estimate, Higher Estimate.
Calculating the percentage of NAs in Compared to National Average
FootNote variable has 59% of data as NAs and hence unusable for analysis. 



```{r}
# NA Analysis and checking the correlation of other variables with Compared to National.

sapply(complications_df[is.na(complications_df$Compared.to.National),],summary)
library(mice)
library(psych)
pairs.panels(x = complications_df[int_comp_var],scale = T,ellipses = T,pch = 20,method = 'pearson',cor = T)
      
```
### Comments: Removing the NAs impacts the the  score. There are 18410 


```{r}
# NA analaysis of the other variables
sapply(complications_df[!is.na(complications_df$Score),],summary)

```

```{r}
#check the correlation between the variables score, denominiator, lower estimate, higher estimate
cor(complications_df[int_comp_var],use = 'complete.obs')
```
#### There is a strong correlation between score, lower.estimate, higher.estimate, negative correlation between the score, Lower.estimate





```{r}
# to lower

```

```{r}
# remove unwanted columns


```



# 1 infections
infected_df <- read.csv(file = "Healthcare Associated Infections - Hospital.csv",header = T,check.names = T,stringsasFactors = T)
View(infected_df)

# 2 Patient Survey
hcahps_survey_hopital_df <- read.csv("HCAHPS - Hospital.csv",header = T,check.names = T,stringsasFactors = T)
hcahps_survey_national_df <- read.csv("HCAHPS - National.csv",header = T,check.names = T,stringsasFactors = T)
hcahps_survey_state_df <- read.csv("HCAHPS - State.csv",header = T,check.names = T,stringsasFactors = T)
View(hcahps_hopital_df)


# 3 General Information
gen_info <- read.csv(file = "Hospital General Information.csv",header = T,check.names = T,stringsasFactors = T)
View(gen_info)

# 4 out patient imaging efficiency
imaging_efficiency <- read.csv(file = "Outpatient Imaging Efficiency - Hospital.csv",header = T,check.names = T,stringsasFactors = T)
View(imaging_efficiency)

# 5 payment and value of care
payment_value_of_care <- read.csv(file = "Payment and Value of Care - Hospital.csv",header = T,check.names = T,stringsasFactors = T)
View(payment_value_of_care)

# 6 readmission deaths
readmission_deaths <- read.csv(file = "Readmissions and Deaths - Hospital.csv",header = T,check.names = T,stringsasFactors = T)
View(readmission_deaths)

# 7 timely effective care
Timely_effective_care <- read.csv(file = "Timely and Effective Care - Hospital.csv",header = T,check.names = T,stringsasFactors = T)
View(Timely_effective_care)

```

## Including Plots

You can also embed plots, for example:

```{r pressure, echo=FALSE}
plot(pressure)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
